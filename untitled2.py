# -*- coding: utf-8 -*-
"""Untitled2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1BX09FmfbWCXE5PbI7nm0IzTeEvYP8T_j
"""



import numpy as np
import matplotlib.pyplot as plt

class MoorePenroseGNN:
    def __init__(self, A, gamma, tol=1e-8, max_iter=5000):
        """
        Initialize the GNN model for Moore-Penrose Inversion.

        Parameters:
        - A: Input matrix (m x n)
        - gamma: Initial learning rate parameter
        - tol: Convergence tolerance
        - max_iter: Maximum number of iterations
        """
        self.A = A
        self.gamma = gamma
        self.tol = tol
        self.max_iter = max_iter
        self.m, self.n = A.shape
        self.X = A.T / np.linalg.norm(A, ord='fro') ** 2
        self.residuals = []  # Store residual norms for plotting

    def compute_residual(self, X):
        """Calculate the residual matrix."""
        return self.A.T @ (self.A @ X - np.eye(self.m))

    def step(self, iteration):
        """Perform one gradient descent step with adaptive learning rate."""
        residual = self.compute_residual(self.X)
        frob_norm = np.linalg.norm(residual, ord='fro')
        self.residuals.append(frob_norm)  # Track the residual norm

        if frob_norm == 0:
            return 0  # Converged exactly

        # Gradient descent update with gradient clipping
        grad = -residual / max(frob_norm, 1e-8)
        adaptive_gamma = self.gamma / (1 + 0.1 * iteration)  # Adaptive learning rate
        self.X += adaptive_gamma * grad

        return frob_norm

    def solve(self):
        """Solve for the Moore-Penrose inverse."""
        for iteration in range(self.max_iter):
            residual_norm = self.step(iteration)
            if residual_norm < self.tol:
                print(f"Converged in {iteration + 1} iterations with residual norm {residual_norm:.2e}.")
                break
        else:
            print("Reached maximum iterations without full convergence.")
        return self.X

    def plot_convergence(self):
        """Plot the convergence behavior."""
        plt.figure(figsize=(8, 6))
        plt.plot(self.residuals, label="Residual Norm")
        plt.yscale('log')  # Logarithmic scale for better visualization
        plt.xlabel('Iteration')
        plt.ylabel('Residual Norm (Frobenius)')
        plt.title('Convergence of Residual Norm')
        plt.legend()
        plt.grid(True)
        plt.show()


def create_matrix_t(t):
    """Generate the matrix A(t)."""
    cos_val = np.cos(np.pi * t / 2)
    sin_val = np.sin(np.pi * t / 2)
    return np.array([
     [cos_val, sin_val],
     [sin_val, -cos_val],
     [cos_val, sin_val]
    ])

""" [1, 2, 3, 4],
    [t, 1+t, 2*t, t**2],
    [cos_val, sin_val, cos_val, sin_val],
    [np.e, np.pi, np.sqrt(2), t] """
""" [cos_val, sin_val],
    [sin_val, -cos_val],
    [cos_val, sin_val] """

if __name__ == "__main__":
    # Test for various values of t
    for t in np.linspace(0, 2, 5):  # Example range for t
        print(f"\nTesting for t = {t}")
        A_t = create_matrix_t(t)
        print("Matrix A(t):")
        print(A_t)

        gamma = 0.1  # Initial learning rate

        # Instantiate and solve for Moore-Penrose inverse
        gnn = MoorePenroseGNN(A_t, gamma=gamma)
        A_pseudo_inverse = gnn.solve()

        print("\nComputed Moore-Penrose Inverse:")
        print(A_pseudo_inverse)

        # Validate the solution
        print("\nValidation (A @ A+ @ A should equal A):")
        print(np.round(A_t @ A_pseudo_inverse @ A_t, decimals=6))

        print("\nValidation (A+ @ A @ A+ should equal A+):")
        print(np.round(A_pseudo_inverse @ A_t @ A_pseudo_inverse, decimals=6))

        # Plot convergence
        gnn.plot_convergence()